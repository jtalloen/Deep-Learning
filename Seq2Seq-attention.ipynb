{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "WP0KJz1qeoex"
   },
   "source": [
    "## Models.py\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ApNIDW-wesGN"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.utils as utils\n",
    "import math as m\n",
    "import random as r\n",
    "\n",
    "DEVICE = 'cuda' if torch.cuda.is_available() else 'cpu'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_B4jFYJrevpb"
   },
   "outputs": [],
   "source": [
    "class Attention(nn.Module):\n",
    "    '''\n",
    "    Attention is calculated using key, value and query from Encoder and decoder.\n",
    "    Below are the set of operations you need to perform for computing attention:\n",
    "        energy = bmm(key, query)\n",
    "        attention = softmax(energy)\n",
    "        context = bmm(attention, value)\n",
    "    '''\n",
    "    def __init__(self):\n",
    "        super(Attention, self).__init__()\n",
    "\n",
    "    def forward(self, query, key, value, linear):\n",
    "        '''\n",
    "        :param query :(N, context_size) Query is the output of LSTMCell from Decoder\n",
    "        :param key: (N, key_size) Key Projection from Encoder per time step\n",
    "        :param value: (N, value_size) Value Projection from Encoder per time step\n",
    "        :return output: Attended Context\n",
    "        :return attention_mask: Attention mask that can be plotted  \n",
    "        '''\n",
    "        # key/ value: (B, seq, value_size)\n",
    "        # query: (B, context) -> (B, context, 1)\n",
    "        # one sentence\n",
    "        # over other words in sentence i.e. in one B\n",
    "\n",
    "        # lens of inputs, use those to create mask \n",
    "        query = query.unsqueeze(2)\n",
    "        energy = torch.bmm(key, query) # key tells you \n",
    "        \n",
    "        X_copy = Variable(linear.data, requires_grad=False) # shifting targets shouldn't change things,\n",
    "        X_copy[X_copy != 0] = 1\n",
    "\n",
    "        attention = nn.functional.softmax(energy, dim=0) # just a weight, adds up to one.  How much weight to weight to put on each time in each value\n",
    "        attention_mask = nn.functional.normalize(attention*X_copy.unsqueeze(2).detach(), p=1)\n",
    "        context = torch.bmm(attention_mask.permute(0,2,1), value)\n",
    "        context_squeeze = context.squeeze(1) # (B, hidden_size) some smaller T right.  This is the total context with weights\n",
    "\n",
    "        return context_squeeze, attention\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "2--NRJ0PeycM"
   },
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "    '''\n",
    "    Encoder takes the utterances as inputs and returns the key and value.\n",
    "    Key and value are nothing but simple projections of the output from pBLSTM network.\n",
    "    '''\n",
    "    def __init__(self, input_dim, hidden_dim, value_size=128,key_size=128):\n",
    "        super(Encoder, self).__init__()\n",
    "        self.hidden_size = hidden_dim\n",
    "\n",
    "        self.lstm = nn.LSTM(input_size=input_dim, hidden_size=hidden_dim, num_layers=1, bidirectional=True, batch_first=True)\n",
    "        \n",
    "        ### Add code to define the blocks of pBLSTMs! ###\n",
    "        self.lstm1 = nn.LSTM(input_size=hidden_dim*4, hidden_size=hidden_dim, num_layers=1, bidirectional=True, batch_first=True)\n",
    "        self.lstm2 = nn.LSTM(input_size=hidden_dim*4, hidden_size=hidden_dim, num_layers=1, bidirectional=True, batch_first=True)\n",
    "        self.lstm3 = nn.LSTM(input_size=hidden_dim*4, hidden_size=hidden_dim, num_layers=1, bidirectional=True, batch_first=True)\n",
    "\n",
    "        # 1024 or 512 to feed into this\n",
    "        self.key_network = nn.Linear(hidden_dim*2, value_size)\n",
    "        self.value_network = nn.Linear(hidden_dim*2, key_size)\n",
    "\n",
    "    def forward(self, x, lens):\n",
    "        batch_size = x.shape[0]\n",
    "\n",
    "        # lstm\n",
    "        rnn_inp = utils.rnn.pack_padded_sequence(x, lengths=lens, batch_first = True, enforce_sorted=False)\n",
    "        outputs, _ = self.lstm(rnn_inp)\n",
    "\n",
    "        # first pblstm\n",
    "        out_1, lens = utils.rnn.pad_packed_sequence(outputs, batch_first=True)\n",
    "        if out_1.shape[1] % 2 != 0:\n",
    "            out_1 = out_1[:, 0:out_1.shape[1]-1, :]  \n",
    "        out_1_reshape = out_1.view(batch_size, int(out_1.shape[1]/2), int(out_1.shape[2]*2))\n",
    "        lens /= 2\n",
    "        packed_out_1 = utils.rnn.pack_padded_sequence(out_1_reshape, lengths=lens, batch_first = True, enforce_sorted=False)\n",
    "        outputs1, _ = self.lstm1(packed_out_1)\n",
    "    \n",
    "        # second pblstm\n",
    "        out_2, lens = utils.rnn.pad_packed_sequence(outputs1, batch_first=True)\n",
    "        if out_2.shape[1] % 2 != 0:\n",
    "            out_2 = out_2[:, 0:out_2.shape[1]-1, :]  \n",
    "        out_2_reshape = out_2.view(batch_size, int(out_2.shape[1]/2), int(out_2.shape[2]*2))\n",
    "        lens /= 2\n",
    "        packed_out_2 = utils.rnn.pack_padded_sequence(out_2_reshape, lengths=lens, batch_first = True, enforce_sorted=False) \n",
    "        outputs2, _ = self.lstm2(packed_out_2)\n",
    "\n",
    "        # third pblstm\n",
    "        out_3, lens = utils.rnn.pad_packed_sequence(outputs2, batch_first=True)\n",
    "        if out_3.shape[1] % 2 != 0:\n",
    "            out_3 = out_3[:, 0:out_3.shape[1]-1, :]  \n",
    "        out_3_reshape = out_3.view(batch_size, int(out_3.shape[1]/2), int(out_3.shape[2]*2))\n",
    "        lens /= 2\n",
    "        packed_out_3 = utils.rnn.pack_padded_sequence(out_3_reshape, lengths=lens, batch_first = True, enforce_sorted=False) \n",
    "        outputs3, _ = self.lstm3(packed_out_3)\n",
    "\n",
    "        # linear \n",
    "        linear_input, final_length = utils.rnn.pad_packed_sequence(outputs3, batch_first = True)\n",
    "        keys = self.key_network(linear_input)\n",
    "        value = self.value_network(linear_input)\n",
    "\n",
    "        return keys, value, final_length, linear_input[:,:,0]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Jc59DExZe1ck"
   },
   "outputs": [],
   "source": [
    "class Decoder(nn.Module):\n",
    "    '''\n",
    "    As mentioned in a previous recitation, each forward call of decoder deals with just one time step, \n",
    "    thus we use LSTMCell instead of LSLTM here.\n",
    "    The output from the second LSTMCell can be used as query here for attention module.\n",
    "    In place of value that we get from the attention, this can be replace by context we get from the attention.\n",
    "    Methods like Gumble noise and teacher forcing can also be incorporated for improving the performance.\n",
    "    '''\n",
    "    def __init__(self, vocab_size, hidden_dim, value_size=128, key_size=128, isAttended=True):\n",
    "        super(Decoder, self).__init__()\n",
    "        self.vocab_size = vocab_size\n",
    "        self.value_size = value_size\n",
    "        self.hidden_size = hidden_dim\n",
    "        \n",
    "        self.embedding = nn.Embedding(vocab_size, hidden_dim, padding_idx=0)\n",
    "        self.lstm1 = nn.LSTMCell(input_size=hidden_dim + value_size, hidden_size=hidden_dim)\n",
    "        self.lstm2 = nn.LSTMCell(input_size=hidden_dim, hidden_size=key_size)\n",
    "\n",
    "        self.isAttended = isAttended\n",
    "        if (isAttended == True):\n",
    "            self.attention = Attention()\n",
    "\n",
    "        self.character_prob = nn.Linear(key_size + value_size, vocab_size)\n",
    "\n",
    "    def forward(self, key, values, text, TF, lengths, isTrain, isVal):\n",
    "        '''\n",
    "        :param key :(T, N, key_size) Output of the Encoder Key projection layer - WE HAVE BATCH FIRST\n",
    "        :param values: (T, N, value_size) Output of the Encoder Value projection layer - WE HAVE BATCH FIRST\n",
    "        :param text: (N, text_len) Batch input of text with text_length - SAME\n",
    "        :param isTrain: Train or eval mode\n",
    "        :return predictions: Returns the character perdiction probability \n",
    "        '''\n",
    "        batch_size = key.shape[0]\n",
    "        # input should be sos to last character\n",
    "        # targets should be first character to eos.\n",
    "\n",
    "        if (isTrain == True or isVal == True):\n",
    "            max_len = text.shape[1]\n",
    "            embeddings = self.embedding(text) # (N, T, hidden_size)\n",
    "        else:\n",
    "            max_len = 250\n",
    "\n",
    "\n",
    "        if (self.isAttended == True):\n",
    "            attn_out = torch.zeros((batch_size, self.value_size))\n",
    "        else:\n",
    "            if values.shape[1] < max_len:\n",
    "                zeros = torch.zeros(batch_size, int(max_len - values.shape[1]), self.value_size).to(DEVICE)\n",
    "                values_new = torch.cat([values, zeros], dim = 1)\n",
    "            else:\n",
    "                values_new = values\n",
    "\n",
    "        predictions = []\n",
    "        hidden_states = [None, None]\n",
    "        prediction = torch.zeros(batch_size, self.vocab_size).to(DEVICE) \n",
    "        prediction[:, 33] = 1 # initialized to <sos> index\n",
    "\n",
    "        for i in range(max_len):\n",
    "            # * Implement Gumble noise and ***teacher forcing*** techniques - w some prob just take char_embed or pred\n",
    "            # * When attention is True, replace values[i,:,:] with the context you get from attention.\n",
    "            # * If you haven't implemented attention yet, then you may want to check the index and break \n",
    "\n",
    "            if (isTrain):\n",
    "                char = embeddings[:,i,:] # check here what embeddings dimensions are\n",
    "                prediction = Gumbel(prediction.to('cpu'), torch.tensor([1-float(TF)])).sample().to(DEVICE)\n",
    "                pred = self.embedding(prediction.argmax(dim=-1))\n",
    "                prob = r.random()\n",
    "                char_embed = char if prob > float(TF) else pred \n",
    "            else:\n",
    "                char_embed = self.embedding(prediction.argmax(dim=-1)) # move up \n",
    "\n",
    "\n",
    "            if (self.isAttended == False):\n",
    "                attn_out = values_new[:,i,:]\n",
    "\n",
    "\n",
    "            inp = torch.cat([char_embed.to(DEVICE), attn_out.to(DEVICE)], dim=1) # context\n",
    "            hidden_states[0] = self.lstm1(inp, hidden_states[0])\n",
    "\n",
    "            inp_2 = hidden_states[0][0]\n",
    "            hidden_states[1] = self.lstm2(inp_2, hidden_states[1])\n",
    "\n",
    "            ### Compute attention from the output of the second LSTM Cell ###\n",
    "            output = hidden_states[1][0]\n",
    "            if (self.isAttended == True):\n",
    "                attn_out, attn_weights = self.attention(output, key, values, lengths) \n",
    "\n",
    "\n",
    "            prediction = self.character_prob(torch.cat([output, attn_out], dim=1)) # (N, vocab_size) # values becomes context\n",
    "            predictions.append(prediction.unsqueeze(1))\n",
    "\n",
    "        return torch.cat(predictions, dim=1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "JTY1XNnHe22a"
   },
   "outputs": [],
   "source": [
    "class Seq2Seq(nn.Module):\n",
    "    '''\n",
    "    We train an end-to-end sequence to sequence model comprising of Encoder and Decoder.\n",
    "    This is simply a wrapper \"model\" for your encoder and decoder.\n",
    "    '''\n",
    "    def __init__(self, input_dim, vocab_size, hidden_dim, value_size=128, key_size=128, isAttended=True):\n",
    "        super(Seq2Seq, self).__init__()\n",
    "        self.encoder = Encoder(input_dim, hidden_dim)\n",
    "        self.decoder = Decoder(vocab_size, hidden_dim)\n",
    "\n",
    "    def forward(self, speech_input, speech_len, text_input, TF, isTrain, isVal):\n",
    "        key, value, lengths, linear = self.encoder(speech_input, speech_len)\n",
    "        if (isTrain == True or isVal == True):\n",
    "            predictions = self.decoder(key, value, text_input, TF, linear, isTrain, isVal)\n",
    "        else:\n",
    "            predictions = self.decoder(key, value, None, TF, linear, isTrain, isVal)\n",
    "        return predictions, lengths, linear\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "0nzhhlKFfawa"
   },
   "source": [
    "## Train_test.py\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "kluOGejufaDG"
   },
   "outputs": [],
   "source": [
    "import time\n",
    "import torch\n",
    "import pdb \n",
    "from torch.autograd import Variable\n",
    "from Levenshtein import distance as levenshtein_distance\n",
    "### Add Your Other Necessary Imports Here! ###\n",
    "\n",
    "DEVICE = 'cuda' if torch.cuda.is_available() else 'cpu'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "YPrfx1jNfe_F"
   },
   "outputs": [],
   "source": [
    "def train(model, train_loader, criterion, optimizer, epoch, TF):\n",
    "    model.train()\n",
    "    model.to(DEVICE)\n",
    "    start = time.time()\n",
    "\n",
    "    # initialize parameters\n",
    "    cum_words = 0.0\n",
    "    cum_loss = 0.0\n",
    "    running_loss = 0.0\n",
    "\n",
    "    # print number of batches\n",
    "    print('='*60)\n",
    "    print(\"Training\", len(train_loader), \"batches\")\n",
    "    print('='*60)\n",
    "\n",
    "    for batch_idx, (X, Y_sos, X_len, Y_len, Y_char_first) in enumerate(train_loader):\n",
    "        torch.autograd.set_detect_anomaly(True)\n",
    "        X = X.to(DEVICE)\n",
    "        Y_sos = Y_sos.to(DEVICE) # all data & model on same device\n",
    "        Y_char_first = Y_char_first.to(DEVICE) # all data & model on same device\n",
    "\n",
    "        # run model and loss\n",
    "        outputs, length, linear = model(X, X_len, Y_sos, TF=TF, isTrain=True, isVal=False) # model here Y needs to be sos to last char\n",
    "        loss = criterion(outputs.view(-1, outputs.shape[2]).float(), Y_char_first.view(-1).long()) # need true label set for criterion i.e. first char to eos\n",
    "        \n",
    "        mask = tor\n",
    "        Y_copy = Variable(Y_sos.data, requires_grad=False) # shifting targets shouldn't change things\n",
    "        outputs_mask = Y_copy.contiguous().view(-1) # need true label set  \n",
    "        outputs_mask[outputs_mask != 0] = 1\n",
    "        loss_mask = (loss*outputs_mask.detach()).sum()\n",
    "        loss_mask.to(DEVICE)\n",
    "        # step backward on masked loss\n",
    "        loss_mask.backward()\n",
    "\n",
    "        # grad clip and step\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), 2)\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # normalize and accumulate masked loss\n",
    "        cum_words += Y_len.sum().item()\n",
    "        cum_loss += loss_mask.item()\n",
    "        perp_mask = m.exp(cum_loss / cum_words)\n",
    "        running_loss = perp_mask\n",
    "\n",
    "        # print loss during batch\n",
    "        mid = time.time()\n",
    "        if batch_idx % 100 == 99:\n",
    "            print('Batch: {:} Cumulative Time: {:.4f}s Train Perplexity: {:.4f}'.format(batch_idx + 1, mid - start, running_loss))\n",
    "            print('='*60)\n",
    "\n",
    "        # delete parameters\n",
    "        torch.cuda.empty_cache()\n",
    "        del perp_mask\n",
    "        del X\n",
    "        del X_len\n",
    "        del Y_len\n",
    "        del Y_char_first\n",
    "        del Y_sos\n",
    "        del loss\n",
    "        del loss_mask\n",
    "        del outputs\n",
    "\n",
    "    end = time.time()\n",
    "    time_final = end - start\n",
    "    return running_loss, time_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "vFAUwzLKffF7"
   },
   "outputs": [],
   "source": [
    "def val(model, val_loader, criterion, optimizer, epoch, TF):\n",
    "    ### Write your test code here! ###\n",
    "    model.eval()\n",
    "    model.to(DEVICE)\n",
    "    start = time.time()\n",
    "\n",
    "    # initialize parameters\n",
    "    cum_words = 0.0\n",
    "    cum_loss = 0.0\n",
    "    running_loss = 0.0\n",
    "    dist = 0.0\n",
    "    total_sentences = 0.0\n",
    "\n",
    "    for batch_idx, (X, Y_sos, X_len, Y_len, Y_char_first) in enumerate(val_loader):\n",
    "        torch.autograd.set_detect_anomaly(True)\n",
    "        X = X.to(DEVICE)\n",
    "        Y_sos = Y_sos.to(DEVICE) # all data & model on same device\n",
    "        Y_char_first = Y_char_first.to(DEVICE) # all data & model on same device\n",
    "\n",
    "        # run model and loss\n",
    "        outputs, length, linear = model(X, X_len, Y_sos, TF=TF, isTrain=False, isVal=True) # model here Y needs to be sos to last char\n",
    "        loss = criterion(outputs.view(-1, outputs.shape[2]).float(), Y_char_first.view(-1).long()) # need true label set for criterion i.e. first char to eos\n",
    "\n",
    "        # calculate masked loss check outputs.  \n",
    "        Y_copy = Variable(Y_sos.data, requires_grad=False) # shifting targets shouldn't change things\n",
    "        outputs_mask = Y_copy.contiguous().view(-1) # need true label set  \n",
    "        outputs_mask[outputs_mask != 0] = 1\n",
    "        loss_mask = (loss*outputs_mask.detach()).sum()\n",
    "        loss_mask.to(DEVICE)\n",
    "\n",
    "        # LD distance\n",
    "        _, character = torch.max(outputs.float(), dim = 2) \n",
    "        for i in range(outputs.shape[0]):\n",
    "            ind_char = np.argwhere(character[i, :].cpu() == 34)\n",
    "            if len(ind_char[0]) > 0:\n",
    "                sent_slice = character[i, :ind_char[0][0].item()]\n",
    "            else:\n",
    "                sent_slice = character[i, :]\n",
    "            \n",
    "            ind_gold = np.argwhere(Y_char_first[i, :].cpu() == 34)\n",
    "            gold_slice = Y_char_first[i, :ind_gold[0][0].item()]\n",
    "            \n",
    "            sentence = ''.join([LETTER_LIST[j] for j in sent_slice]) \n",
    "            sentence_gold = ''.join([LETTER_LIST[j] for j in gold_slice])\n",
    "            dist += levenshtein_distance(sentence, sentence_gold)\n",
    "\n",
    "\n",
    "        # normalize and accumulate masked perp\n",
    "        cum_words += Y_len.sum().item()\n",
    "        cum_loss += loss_mask.item()\n",
    "        perp_mask = m.exp(cum_loss / cum_words)\n",
    "        running_loss = perp_mask\n",
    "\n",
    "        total_sentences += outputs.shape[0]\n",
    "        avg_dist = dist / total_sentences\n",
    "        \n",
    "        # delete parameters\n",
    "        torch.cuda.empty_cache()\n",
    "        del perp_mask\n",
    "        del X\n",
    "        del X_len\n",
    "        del Y_len\n",
    "        del Y_char_first\n",
    "        del Y_sos\n",
    "        del loss\n",
    "        del loss_mask\n",
    "        del outputs\n",
    "\n",
    "    end = time.time()\n",
    "    time_final = end - start\n",
    "    return running_loss, time_final, avg_dist\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "_jfjiDRJdCib"
   },
   "source": [
    "## Dataloader.py\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "bWFgo7PEdGj_"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data import Dataset \n",
    "from torch.nn.utils.rnn import *\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-i5aUcE4dGnX"
   },
   "outputs": [],
   "source": [
    "'''\n",
    "Loading all the numpy files containing the utterance information and text information\n",
    "'''\n",
    "def load_data():\n",
    "    speech_train = np.load('train_new.npy', allow_pickle=True, encoding='bytes')\n",
    "    speech_valid = np.load('dev_new.npy', allow_pickle=True, encoding='bytes')\n",
    "    speech_test = np.load('test_new.npy', allow_pickle=True, encoding='bytes')\n",
    "\n",
    "    transcript_train = np.load('./train_transcripts.npy', allow_pickle=True,encoding='bytes')\n",
    "    transcript_valid = np.load('./dev_transcripts.npy', allow_pickle=True,encoding='bytes')\n",
    "\n",
    "    return speech_train, speech_valid, speech_test, transcript_train, transcript_valid\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "O2AhfTnGdQ-2"
   },
   "outputs": [],
   "source": [
    "'''\n",
    "Transforms alphabetical input to numerical input, replace each letter by its corresponding \n",
    "index from letter_list\n",
    "'''\n",
    "def transform_letter_to_index(transcript, letter_list):\n",
    "    '''\n",
    "    :param transcript :(N, ) Transcripts are the text input\n",
    "    :param letter_list: Letter list defined above\n",
    "    :return letter_to_index_list: Returns a list for all the transcript sentence to index\n",
    "    '''\n",
    "    idx_transcript = []\n",
    "\n",
    "    for i, arr in enumerate(transcript):\n",
    "        idx_arr = [letter_list.index('<sos>')]\n",
    "        # idx_arr.append(letter_list.index(' '))\n",
    "\n",
    "        for j, word in enumerate(arr):\n",
    "            str_word = word.decode('UTF-8')\n",
    "            for k, letter in enumerate(str_word):\n",
    "                idx_letter = letter_list.index(letter)\n",
    "                idx_arr.append(idx_letter)\n",
    "\n",
    "            if j == len(arr)-1:\n",
    "                idx_arr.append(letter_list.index('<eos>'))\n",
    "            else:\n",
    "                idx_arr.append(letter_list.index(' '))\n",
    "\n",
    "        idx_transcript.append(np.array(idx_arr))\n",
    "\n",
    "    nump_idx_transcript = np.array(idx_transcript)\n",
    "\n",
    "    return nump_idx_transcript"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "2p5T0CWQdTwr"
   },
   "outputs": [],
   "source": [
    "\n",
    "class Speech2TextDataset(Dataset):\n",
    "    '''\n",
    "    Dataset class for the speech to text data, this may need some tweaking in the\n",
    "    getitem method as your implementation in the collate function may be different from\n",
    "    ours. \n",
    "    '''\n",
    "    def __init__(self, speech, text=None, isTrain=True):\n",
    "        self.speech = speech\n",
    "        self.isTrain = isTrain\n",
    "        if (text is not None):\n",
    "            self.text = text\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.speech.shape[0]\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        if (self.isTrain == True):\n",
    "            return torch.tensor(self.speech[index].astype(np.float32)), torch.tensor(self.text[index])\n",
    "        else:\n",
    "            return torch.tensor(self.speech[index].astype(np.float32))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "qIUkWKB0dVQo"
   },
   "outputs": [],
   "source": [
    "def collate_train(batch_data):\n",
    "    ### Return the padded speech and text data, and the length of utterance and transcript ###\n",
    "    inputs, targets = zip(*batch_data)\n",
    "\n",
    "    lens_inp = [len(seq) for seq in inputs]\n",
    "    lens_tar = [len(seq) for seq in targets]\n",
    "\n",
    "    inputs = [torch.FloatTensor(inputs[i]) for i in range(len(inputs))]\n",
    "    targets_sos = [torch.LongTensor(targets[i][:-1]) for i in range(len(targets))]\n",
    "    targets_first_char = [torch.LongTensor(targets[i][1:]) for i in range(len(targets))]\n",
    "\n",
    "    inputs_pad = pad_sequence(inputs, batch_first = True, padding_value = 0)\n",
    "    targets_sos_pad = pad_sequence(targets_sos, batch_first = True, padding_value = 0)\n",
    "    targets_first_char_pad = pad_sequence(targets_first_char, batch_first = True, padding_value = 0)\n",
    "\n",
    "    return inputs_pad, targets_sos_pad, torch.LongTensor(lens_inp), torch.LongTensor(lens_tar), targets_first_char_pad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ouNrxRCkdWr9"
   },
   "outputs": [],
   "source": [
    "def collate_test(batch_data):\n",
    "    ### Return padded speech and length of utterance ###\n",
    "    inputs = batch_data\n",
    "    lens_inp = [len(seq) for seq in inputs]\n",
    "    inputs = [torch.FloatTensor(inputs[i]) for i in range(len(inputs))]\n",
    "    inputs_pad = pad_sequence(inputs, batch_first = True, padding_value = 0)\n",
    "\n",
    "    return inputs_pad, torch.LongTensor(lens_inp)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "6SiDeE7odHPz"
   },
   "source": [
    "## Main.py\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "east0cS7dLMb"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.distributions.gumbel import Gumbel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 50
    },
    "colab_type": "code",
    "id": "lTY0PkOSdLO3",
    "outputId": "9428901c-aabd-4544-d4fc-f62dc0a17ddf"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "35\n",
      "cuda\n"
     ]
    }
   ],
   "source": [
    "DEVICE = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "LETTER_LIST = ['<pad>', 'A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'L', 'M', 'N', 'O', 'P', 'Q', \\\n",
    "               'R', 'S', 'T', 'U', 'V', 'W', 'X', 'Y', 'Z', '-', \"'\", '.', '_', '+', ' ','<sos>','<eos>']\n",
    "\n",
    "print(len(LETTER_LIST))\n",
    "print(DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def weights_init(layer):\n",
    "    if isinstance(layer, nn.Embedding):\n",
    "        torch.nn.init.uniform_(layer.weight.data, a=-0.1, b=0.1)\n",
    "    elif isinstance(layer, nn.LSTM):\n",
    "        for param in layer.parameters():\n",
    "            if len(param.shape) >= 2: # weights\n",
    "                torch.nn.init.orthogonal_(param.data)\n",
    "            else: # beta\n",
    "                torch.nn.init.normal_(param.data)\n",
    "    elif isinstance(layer, nn.LSTMCell):\n",
    "        for param in layer.parameters():\n",
    "            if len(param.shape) >= 2:\n",
    "                torch.nn.init.orthogonal_(param.data)\n",
    "            else:\n",
    "                torch.nn.init.normal_(param.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "7hD5REqnifMO"
   },
   "outputs": [],
   "source": [
    "model = Seq2Seq(input_dim=40, vocab_size=len(LETTER_LIST), hidden_dim=256)\n",
    "model.apply(weights_init)\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-3) \n",
    "criterion = nn.CrossEntropyLoss(reduction='none')\n",
    "nepochs = 100\n",
    "batch_size = 64 if DEVICE == 'cuda' else 2\n",
    "\n",
    "speech_train, speech_valid, speech_test, transcript_train, transcript_valid = load_data()\n",
    "\n",
    "character_text_train = transform_letter_to_index(transcript_train, LETTER_LIST)\n",
    "character_text_valid = transform_letter_to_index(transcript_valid, LETTER_LIST)\n",
    "\n",
    "train_dataset = Speech2TextDataset(speech_train, character_text_train)\n",
    "val_dataset = Speech2TextDataset(speech_valid, character_text_valid)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, collate_fn=collate_train)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False, collate_fn=collate_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range(1, nepochs+1):\n",
    "    log = open(name + \"_logs.txt\", \"a\")\n",
    "    if epoch == 4 or epoch == 7 or epoch == 10: TF += 0.1\n",
    "    if epoch == 25 or epoch == 40: TF += 0.1\n",
    "    if epoch == 25: optimizer = optim.Adam(model.parameters(), lr=5e-4)\n",
    "    if epoch == 30: optimizer = optim.Adam(model.parameters(), lr=1e-4)\n",
    "#     model.load_state_dict(torch.load('normalize_weight_init_epoch_' + str(epoch) + '_model.pt'))\n",
    "\n",
    "    # train\n",
    "    perplexity_train, time_train = train(model, train_loader, criterion, optimizer, epoch, TF)\n",
    "    print('Epoch: {:.0f} Train Time: {:.4f}s Train Perplexity: {:.4f}'.format(epoch, time_train, perplexity_train))\n",
    "    log.write('Epoch: {:.0f} Train Time: {:.4f}s Train Perplexity: {:.4f}\\n'.format(epoch, time_train, perplexity_train)) \n",
    "\n",
    "    # val\n",
    "    perplexity_val, time_val, avg_dist = val(model, val_loader, criterion, optimizer, epoch, TF) \n",
    "    print('Epoch: {:.0f} Val Time: {:.4f}s Val Perplexity: {:.4f} Val dist: {:.2f}'.format(epoch, time_val, perplexity_val, avg_dist))\n",
    "    log.write('Epoch: {:.0f} Val Time: {:.4f}s Val Perplexity: {:.4f} Val dist: {:.2f}\\n'.format(epoch, time_val, perplexity_val, avg_dist))\n",
    "\n",
    "    \n",
    "    print('='*60)\n",
    "    log.write('='*60 + '\\n')\n",
    "    log.close()\n",
    "\n",
    "    # save model\n",
    "    torch.save(model.state_dict(), name + '_epoch_' + str(epoch) + '_model.pt')\n",
    "#     torch.save(optimizer.state_dict(), name + '_epoch_' + str(epoch) + '_optimizer.pt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "MKKHsdSgSVc4"
   },
   "source": [
    "## Write_test.py\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "8v-VWdV2Shj9"
   },
   "outputs": [],
   "source": [
    "test_dataset = Speech2TextDataset(speech_test, None, False)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False, collate_fn=collate_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "ntqcwXzOS8qm",
    "outputId": "c3518b19-0acb-4a3e-d13b-f19f8faabd7a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testout = open(\"submission.csv\", \"w\")\n",
    "testout.write('Id,Predicted\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "w7MToLrIScrx"
   },
   "outputs": [],
   "source": [
    "\n",
    "model.load_state_dict(torch.load(\"weight_gumbel_epoch_83_model.pt\"))\n",
    "\n",
    "model.eval()\n",
    "model.to(DEVICE)\n",
    "batch_size = 64\n",
    "for batch_idx, (X, X_len) in enumerate(test_loader):\n",
    "    X = X.to(DEVICE)\n",
    "\n",
    "    # run model and do greedy search\n",
    "    outputs, _, _ = model(X, X_len, None, TF=TF, isTrain=False, isVal=False) \n",
    "    _, character = torch.max(outputs.float(), dim = 2) \n",
    "\n",
    "    for i in range(X.shape[0]):\n",
    "        indx = batch_idx*batch_size + i\n",
    "        ind_char = np.argwhere(character[i, :].cpu() == 34)\n",
    "        if len(ind_char[0]) > 0:\n",
    "#             print(ind_char)\n",
    "            sent_slice = character[i, :ind_char[0][0].item()]\n",
    "        else:\n",
    "            sent_slice = character[i, :]\n",
    "            \n",
    "        sentence = ''.join([LETTER_LIST[j] for j in sent_slice]) # just to be clear eos should not be printed right\n",
    "\n",
    "        testout.write(str(indx) + \",\" + str(sentence) + '\\n')       \n",
    "\n",
    "testout.close()"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "machine_shape": "hm",
   "name": "hw4p2.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
